@misc{reynolds2021promptprogramminglargelanguage,
      title={Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm}, 
      author={Laria Reynolds and Kyle McDonell},
      year={2021},
      eprint={2102.07350},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2102.07350}, 
}

@misc{wei2022emergentabilitieslargelanguage,
      title={Emergent Abilities of Large Language Models}, 
      author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
      year={2022},
      eprint={2206.07682},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.07682}, 
}
@article{lstm,
author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
year = {1997},
month = {12},
pages = {1735-80},
title = {Long Short-term Memory},
volume = {9},
journal = {Neural computation},
doi = {10.1162/neco.1997.9.8.1735}
}
@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@misc{liu2021pretrainpromptpredictsystematic,
      title={Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing}, 
      author={Pengfei Liu and Weizhe Yuan and Jinlan Fu and Zhengbao Jiang and Hiroaki Hayashi and Graham Neubig},
      year={2021},
      eprint={2107.13586},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2107.13586}, 
}

@InProceedings{luan2018multitask,
     author = {Luan, Yi and He, Luheng and Ostendorf, Mari and Hajishirzi, Hannaneh},
     title = {Multi-Task Identification of Entities, Relations, and Coreferencefor Scientific Knowledge Graph Construction},
     booktitle = {Proc.\ Conf. Empirical Methods Natural Language Process. (EMNLP)},
     year = {2018},
}

@article{liu2021token,
  title={A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation},
  author={Liu, Tianyu and Zhang, Yizhe and Brockett, Chris and Mao, Yi and Sui, Zhifang and Chen, Weizhu and Dolan, Bill},
  journal={arXiv preprint arXiv:2104.08704},
  year={2021}
}

@article{li2019unified,
  title={A unified MRC framework for named entity recognition},
  author={Li, Xiaoya and Feng, Jingrong and Meng, Yuxian and Han, Qinghong and Wu, Fei and Li, Jiwei},
  journal={arXiv preprint arXiv:1910.11476},
  year={2019}
}

@article{ye2021packed,
  title={Packed levitated marker for entity and relation extraction},
  author={Ye, Deming and Lin, Yankai and Li, Peng and Sun, Maosong},
  journal={arXiv preprint arXiv:2109.06067},
  year={2021}
}

@article{beltagy2019scibert,
  title={SciBERT: A pretrained language model for scientific text},
  author={Beltagy, Iz and Lo, Kyle and Cohan, Arman},
  journal={arXiv preprint arXiv:1903.10676},
  year={2019}
}

@article{wang2018glue,
  title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}

@article{yu2020relationship,
  title={A relationship extraction method for domain knowledge graph construction},
  author={Yu, Haoze and Li, Haisheng and Mao, Dianhui and Cai, Qiang},
  journal={World Wide Web},
  volume={23},
  number={2},
  pages={735--753},
  year={2020},
  publisher={Springer}
}


@inproceedings{semeval,
    title = "{S}em{E}val-2007 Task 14: Affective Text",
    author = "Strapparava, Carlo  and
      Mihalcea, Rada",
    booktitle = "Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007)",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S07-1013",
    pages = "70--74",
}
 
 @article{anoop22readers,
author={K., Anoop
and P., Deepak
and Sam Abraham, Savitha
and V. L., Lajish
and P. Gangan, Manjary},
title={Readers' affect: predicting and understanding readers' emotions with deep learning},
journal={Journal of Big Data},
year={2022},
month={Jun},
day={20},
volume={9},
number={1},
pages={82},
abstract={Emotions are highly useful to model human behavior being at the core of what makes us human. Today, people abundantly express and share emotions through social media. Technological advancements in such platforms enable sharing opinions or expressing any specific emotions towards what others have shared, mainly in the form of textual data. This entails an interesting arena for analysis; as to whether there is a disconnect between the writer's intended emotion and the reader's perception of textual content. In this paper, we present experiments for Readers' Emotion Detection through multi-target regression settings by exploring a Bi-LSTM-based Attention model, where our major intention is to analyze the interpretability and effectiveness of the deep learning model for the task. To conduct experiments, we procure two extensive datasets REN-10k and RENh-4k, apart from using a popular benchmark dataset from SemEval-2007. We perform a two-phase experimental evaluation, first being various coarse-grained and fine-grained evaluations of our model performance in comparison with several baselines belonging to different categories of emotion detection, viz., deep learning, lexicon based, and classical machine learning. Secondly, we evaluate model behavior towards readers' emotion detection assessing attention maps generated by the model through devising a novel set of qualitative and quantitative metrics. The first phase of experiments shows that our Bi-LSTM + Attention model significantly outperforms all baselines. The second analysis reveals that emotions may be correlated to specific words as well as named entities.},
issn={2196-1115},
doi={10.1186/s40537-022-00614-2},
url={https://doi.org/10.1186/s40537-022-00614-2}
}

@inproceedings{bias,
    title = "We Can Detect Your Bias: Predicting the Political Ideology of News Articles",
    author = "Baly, Ramy  and
      Da San Martino, Giovanni  and
      Glass, James  and
      Nakov, Preslav",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.404",
    doi = "10.18653/v1/2020.emnlp-main.404",
    pages = "4982--4991",
    abstract = "We explore the task of predicting the leading political ideology or bias of news articles. First, we collect and release a large dataset of 34,737 articles that were manually annotated for political ideology {--}left, center, or right{--}, which is well-balanced across both topics and media. We further use a challenging experimental setup where the test examples come from media that were not seen during training, which prevents the model from learning to detect the source of the target news article instead of predicting its political ideology. From a modeling perspective, we propose an adversarial media adaptation, as well as a specially adapted triplet loss. We further add background information about the source, and we show that it is quite helpful for improving article-level prediction. Our experimental results show very sizable improvements over using state-of-the-art pre-trained Transformers in this challenging setup.",
}

@misc{xu2023peerda,
      title={PeerDA: Data Augmentation via Modeling Peer Relation for Span Identification Tasks}, 
      author={Weiwen Xu and Xin Li and Yang Deng and Wai Lam and Lidong Bing},
      year={2023},
      eprint={2210.08855},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ravikiran2022findings,
      title={Findings of the Shared Task on Offensive Span Identification from Code-Mixed Tamil-English Comments}, 
      author={Manikandan Ravikiran and Bharathi Raja Chakravarthi and Anand Kumar Madasamy and Sangeetha Sivanesan and Ratnavel Rajalakshmi and Sajeetha Thavareesan and Rahul Ponnusamy and Shankar Mahadevan},
      year={2022},
      eprint={2205.06118},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{dewantara-etal-2020-3218ir,
    title = "3218{IR} at {S}em{E}val-2020 Task 11: {C}onv1{D} and Word Embedding in Propaganda Span Identification at News Articles",
    author = "Dewantara, Dimas Sony  and
      Budi, Indra  and
      Ibrohim, Muhammad Okky",
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    address = "Barcelona (online)",
    publisher = "International Committee for Computational Linguistics",
    url = "https://aclanthology.org/2020.semeval-1.225",
    doi = "10.18653/v1/2020.semeval-1.225",
    pages = "1716--1721",
    abstract = "In this paper, we present the result of our experiment with a variant of 1 Dimensional Convolutional Neural Network (Conv1D) hyper-parameters value. We describe the system entered by the team of Information Retrieval Lab. Universitas Indonesia (3218IR) in the SemEval 2020 Task 11 Sub Task 1 about propaganda span identification in news articles. The best model obtained an F1 score of 0.24 in the development set and 0.23 in the test set. We show that there is a potential for performance improvement through the use of models with appropriate hyper-parameters. Our system uses a combination of Conv1D and GloVe as Word Embedding to detect propaganda in the fragment text level.",
}

@misc{papay2020dissecting,
      title={Dissecting Span Identification Tasks with Performance Prediction}, 
      author={Sean Papay and Roman Klinger and Sebastian Padó},
      year={2020},
      eprint={2010.02587},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

﻿@Article{Ma2018,
author={Ma, Shutian
and Xu, Jin
and Zhang, Chengzhi},
title={Automatic identification of cited text spans: a multi-classifier approach over imbalanced dataset},
journal={Scientometrics},
year={2018},
month={Aug},
day={01},
volume={116},
number={2},
pages={1303-1330},
abstract={Recently, a new form of structured summary on scientific papers is explored by grouping cited text spans from the reference paper. Its primary goal is to generate summaries based on the cited paper itself. Previously, traditional scientific summarization focused on citation-based methods by aggregating all citances that cite one unique paper without doing content-based citation analysis, while sometimes citations might differ between researchers or time slots. By investigating original text spans where scholars cited, the new method can reflect exact contributions of reference papers more. Therefore, how to identify cited text spans accurately becomes the first important problem to solve. Generally, it can be converted into finding the sentences in reference paper that is more similar with citation sentences. Taking it as a classification task, we investigate the potential of four actions to improve identification performance. Firstly, feature selections are conducted carefully according to multi-classifiers. Secondly, we apply sampling-based algorithms to preprocess class-imbalanced datasets. Since we integrated results via a weighted voting system, the third action is tuning parameters like, voting weights for multi-classifiers integration or running settings to see if we can improve performance further. Evaluation results show effectiveness of each action and demonstrate that researchers can take these actions for more accurate cited text spans identification when doing scientific summarization.},
issn={1588-2861},
doi={10.1007/s11192-018-2754-2},
url={https://doi.org/10.1007/s11192-018-2754-2}
}

@article{la2019poli2sum,
  title={Poli2Sum@ CL-SciSumm-19: Identify, Classify, and Summarize Cited Text Spans by means of Ensembles of Supervised Models.},
  author={La Quatra, Moreno and Cagliero, Luca and Baralis, Elena and others},
  journal={BIRNDL@ SIGIR},
  volume={2414},
  pages={233--246},
  year={2019}
}

@inproceedings{ravikiran-annamalai-2021-dosa,
    title = "{DOSA}: {D}ravidian Code-Mixed Offensive Span Identification Dataset",
    author = "Ravikiran, Manikandan  and
      Annamalai, Subbiah",
    booktitle = "Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages",
    month = apr,
    year = "2021",
    address = "Kyiv",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.dravidianlangtech-1.2",
    pages = "10--17",
    abstract = "This paper presents the Dravidian Offensive Span Identification Dataset (DOSA) for under-resourced Tamil-English and Kannada-English code-mixed text. The dataset addresses the lack of code-mixed datasets with annotated offensive spans by extending annotations of existing code-mixed offensive language identification datasets. It provides span annotations for Tamil-English and Kannada-English code-mixed comments posted by users on YouTube social media. Overall the dataset consists of 4786 Tamil-English comments with 6202 annotated spans and 1097 Kannada-English comments with 1641 annotated spans, each annotated by two different annotators. We further present some of our baseline experimental results on the developed dataset, thereby eliciting research in under-resourced languages, leading to an essential step towards semi-automated content moderation in Dravidian languages. The dataset is available in \url{https://github.com/teamdl-mlsg/DOSA}",
}

@misc{toshniwal2020crosstask,
      title={A Cross-Task Analysis of Text Span Representations}, 
      author={Shubham Toshniwal and Haoyue Shi and Bowen Shi and Lingyu Gao and Karen Livescu and Kevin Gimpel},
      year={2020},
      eprint={2006.03866},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{joshi2020spanbert,
  title={Spanbert: Improving pre-training by representing and predicting spans},
  author={Joshi, Mandar and Chen, Danqi and Liu, Yinhan and Weld, Daniel S and Zettlemoyer, Luke and Levy, Omer},
  journal={Transactions of the association for computational linguistics},
  volume={8},
  pages={64--77},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{ranasinghe2021wlv,
  title={WLV-RIT at SemEval-2021 task 5: A neural transformer framework for detecting toxic spans},
  author={Ranasinghe, Tharindu and Sarkar, Diptanu and Zampieri, Marcos and Ororbia, Alexander},
  journal={arXiv preprint arXiv:2104.04630},
  year={2021}
}

@article{chen2020improving,
  title={Improving the efficiency of grammatical error correction with erroneous span detection and correction},
  author={Chen, Mengyun and Ge, Tao and Zhang, Xingxing and Wei, Furu and Zhou, Ming},
  journal={arXiv preprint arXiv:2010.03260},
  year={2020}
}

@article{liu2021sent2span,
  title={Sent2Span: span detection for PICO extraction in the biomedical text without span annotations},
  author={Liu, Shifeng and Sun, Yifang and Li, Bing and Wang, Wei and Bourgeois, Florence T and Dunn, Adam G},
  journal={arXiv preprint arXiv:2109.02254},
  year={2021}
}

@article{abaho2021detect,
  title={Detect and Classify--Joint Span Detection and Classification for Health Outcomes},
  author={Abaho, Michael and Bollegala, Danushka and Williamson, Paula and Dodd, Susanna},
  journal={arXiv preprint arXiv:2104.07789},
  year={2021}
}

@inproceedings{nouri2022data,
  title={Data Augmentation with Dual Training for Offensive Span Detection},
  author={Nouri, Nasim},
  booktitle={Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={2569--2575},
  year={2022}
}

@inproceedings{yeung2015automatic,
  title={Automatic detection of sentence fragments},
  author={Yeung, Chak Yan and Lee, John SY},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  pages={599--603},
  year={2015}
}

@inproceedings{pavlopoulos2021semeval,
  title={SemEval-2021 task 5: Toxic spans detection},
  author={Pavlopoulos, John and Sorensen, Jeffrey and Laugier, L{\'e}o and Androutsopoulos, Ion},
  booktitle={Proceedings of the 15th international workshop on semantic evaluation (SemEval-2021)},
  pages={59--69},
  year={2021}
}

@article{martino2020semeval,
  title={SemEval-2020 task 11: Detection of propaganda techniques in news articles},
  author={Martino, G and Barr{\'o}n-Cedeno, Alberto and Wachsmuth, Henning and Petrov, Rostislav and Nakov, Preslav},
  journal={arXiv preprint arXiv:2009.02696},
  year={2020}
}

@article{jurkiewicz2020applicaai,
  title={ApplicaAI at SemEval-2020 task 11: On RoBERTa-CRF, span CLS and whether self-training helps them},
  author={Jurkiewicz, Dawid and Borchmann, {\L}ukasz and Kosmala, Izabela and Grali{\'n}ski, Filip},
  journal={arXiv preprint arXiv:2005.07934},
  year={2020}
}

@article{li2019unified,
  title={A unified MRC framework for named entity recognition},
  author={Li, Xiaoya and Feng, Jingrong and Meng, Yuxian and Han, Qinghong and Wu, Fei and Li, Jiwei},
  journal={arXiv preprint arXiv:1910.11476},
  year={2019}
}

@article{martino2019fine,
  title={Fine-grained analysis of propaganda in news articles},
  author={Martino, Giovanni Da San and Yu, Seunghak and Barr{\'o}n-Cede{\~n}o, Alberto and Petrov, Rostislav and Nakov, Preslav},
  journal={arXiv preprint arXiv:1910.02517},
  year={2019}
}

@inproceedings{rojas2022simple,
  title={Simple yet powerful: An overlooked architecture for nested named entity recognition},
  author={Rojas, Mat{\'\i}as and Bravo-Marquez, Felipe and Dunstan, Jocelyn},
  booktitle={Proceedings of the 29th International Conference on Computational Linguistics},
  pages={2108--2117},
  year={2022}
}

@article{garimella2018quantifying,
  title={Quantifying controversy on social media},
  author={Garimella, Kiran and Morales, Gianmarco De Francisci and Gionis, Aristides and Mathioudakis, Michael},
  journal={ACM Transactions on Social Computing},
  volume={1},
  number={1},
  pages={1--27},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{cheng2020ape,
  title={APE: Argument pair extraction from peer review and rebuttal via multi-task learning},
  author={Cheng, Liying and Bing, Lidong and Yu, Qian and Lu, Wei and Si, Luo},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={7000--7011},
  year={2020}
}

@article{baly2020we,
  title={We can detect your bias: Predicting the political ideology of news articles},
  author={Baly, Ramy and Martino, Giovanni Da San and Glass, James and Nakov, Preslav},
  journal={arXiv preprint arXiv:2010.05338},
  year={2020}
}

@inproceedings{strapparava2007semeval,
  title={Semeval-2007 task 14: Affective text},
  author={Strapparava, Carlo and Mihalcea, Rada},
  booktitle={Proceedings of the fourth international workshop on semantic evaluations (SemEval-2007)},
  pages={70--74},
  year={2007}
}

@inproceedings{zaratiana2022gnner,
  title={GNNer: Reducing overlapping in span-based NER using graph neural networks},
  author={Zaratiana, Urchade and Tomeh, Nadi and Holat, Pierre and Charnois, Thierry},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop},
  pages={97--103},
  year={2022}
}

@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{mutz2010mass,
  title={Mass media},
  author={Mutz, Diana and Goldman, Seth},
  year={2010}
}

@inproceedings{kemahduta2021automatic,
  title={Automatic Text Summarization with Categorization on Online News About Indonesian Public Figures Using Fuzzy Logic Method},
  author={Kemahduta, Sigi and Sihwi, Sari Widya and Widiarto, Wisnu},
  booktitle={2021 International Conference on Artificial Intelligence and Big Data Analytics},
  pages={10--15},
  year={2021},
  organization={IEEE}
}


@misc{zmitrovich2023family,
      title={A Family of Pretrained Transformer Language Models for Russian}, 
      author={Dmitry Zmitrovich and Alexander Abramov and Andrey Kalmykov and Maria Tikhonova and Ekaterina Taktasheva and Danil Astafurov and Mark Baushenko and Artem Snegirev and Tatiana Shavrina and Sergey Markov and Vladislav Mikhailov and Alena Fenogenova},
      year={2023},
      eprint={2309.10931},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{kuratov2019adaptation,
      title={Adaptation of Deep Bidirectional Multilingual Transformers for Russian Language}, 
      author={Yuri Kuratov and Mikhail Arkhipov},
      year={2019},
      eprint={1905.07213},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{guo2020cyclegt,
      title={CycleGT: Unsupervised Graph-to-Text and Text-to-Graph Generation via Cycle Training}, 
      author={Qipeng Guo and Zhijing Jin and Xipeng Qiu and Weinan Zhang and David Wipf and Zheng Zhang},
      year={2020},
      eprint={2006.04702},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}