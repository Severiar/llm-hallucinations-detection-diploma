\documentclass[12pt]{article}
\usepackage{arxiv}


\usepackage[colorlinks=true,linkcolor=blue]{hyperref}

\textheight=24cm
\textwidth=16cm
\oddsidemargin=5mm
\evensidemargin=-5mm
\marginparwidth=36pt
\topmargin=-2cm
\footskip=2.5em
\footnotesep=2ex




\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage[square,numbers]{natbib}
\usepackage{doi}

\usepackage{svg}

\usepackage{multirow}
\usepackage{ragged2e}
\usepackage{indentfirst}
\usepackage{multicol}
\usepackage{subfig}
\usepackage{amsmath,amssymb}
\usepackage{enumerate}
\usepackage{mathtools}
\usepackage{comment}
\usepackage{multicol}

\graphicspath{ {./images/} }

\title{Выделение графовых структур в тексте с помощью больших языковых моделей}

\author{ Левыкин Александр Михайлович \\
        Факультет вычислительной математики и кибернетики \\
        МГУ им. Ломоносова \\
        \texttt{s02210450@gmail.com} \\
	%% examples of more authors
	\And
	Воронцов Константин Вячеславович \\
        Факультет вычислительной математики и кибернетики \\
        МГУ им. Ломоносова \\
        \texttt{vokov@forecsys.ru} \\
}
\date{}

\renewcommand{\shorttitle}{\textit{arXiv} Template}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={A template for the arxiv style},
pdfsubject={q-bio.NC, q-bio.QM},
pdfauthor={David S.~Hippocampus, Elias D.~Striatum},
pdfkeywords={First keyword, Second keyword, More},
}

\begin{document}

\maketitle

\begin{abstract}
В данной работе рассматривается задача детекции галлюцинаций больших языковых моделей. Основное внимание уделяется решению задачи в token classification постановке, в которой требуется классифицировать на наличие галлюцинаций каждый токен ответа модели. Кроме того, фокус направлен на детекцию фактологических галлюцинаций для задачи в reference-free постановке и подход со сведением её к reference-based. Анализируются подходы instruction-based, дообучение NER моделей, а также анализ временных рядов. %Дополнительно рассматривается задача, в которой для фрагментов размечена степень уверенности, с которой он был отнесён к галлюцинации, и соответствующие такому подходу критерии оценки качества моделей детекции.%

%В данной работе рассматривается задача выделения связей в тексте на примере данных scierc. Сравниваются различные векторные представления фрагментов текста для классификации связей. Представляется модход MRC для классификации связей между фрагментами. Для задачи совместного выделения фрагментов и связей представляется новый критерий оценивания, который учитывает неточности выделения фрагментов и неточности классификации связей. Данный критерий сглаживает F-меру и ослабляет требования.
%
\end{abstract}


\section{Введение}
Задача детекции галлюцинаций в больших языковых моделях (Large Language Models, LLM) является одной из подзадач обработки естественного языка (NLP), которая направлена на выявление ложных или недостоверных ответов, генерируемых моделями. Галлюцинации могут проявляться в виде неправдивых утверждений, вымышленных данных и фактов, что ограничивает точность и применимость LLM в ряде критически важных задач. Детекция таких ошибок критически важна в областях, где на основе необходима для обеспечения надежности и повышения доверия к моделям в реальных приложениях.

Применение детекции галлюцинаций может быть полезно в следующих областях:
\begin{itemize}
    \item В создании автоматических систем поддержки решений (например, в медицине или праве) идентификация ложных данных в ответах модели помогает минимизировать риски и избегать принятия решений на основе недостоверной информации [1].
    \item В задачах генерации текстов и чат-ботах применение детекции галлюцинаций позволяет улучшить качество и достоверность предоставляемых ответов, помогая пользователям получать более точную информацию [2].
    \item В аналитике социальных медиа и маркетинговых исследованиях детекция галлюцинаций позволяет более эффективно анализировать настроения и тренды, исключая из анализа ложные и искаженные данные [3].
\end{itemize}
Галлюцинация LLM — это ответ (или его часть), сгенерированный моделью, который не соответствует входным данным (промпту) или ранее сгенерированному контексту, либо противоречит общеизвестным фактам о мире. 

Задачи детекции галлюцинаций в больших языковых моделях можно классифицировать по нескольким основным признакам, включая подходы к детекции, использование эталонных данных и уровень детализации анализа. 
\begin{enumerate}
\item Детекция галлюцинаций с использованием эталонных данных (reference-based hallucination detection)  
   Одним из распространённых методов является эталонная (reference-based) детекция галлюцинаций, при которой сгенерированный текст сравнивается с имеющимся эталоном. Этот подход успешно применяется в таких задачах, как абстрактное суммирование текста (Maynez et al., 2020), машинный перевод (Wang and Sennrich, 2020), генерация текста на основе данных (Rebuffel et al., 2021) и создание подписей к изображениям (Rohrbach et al., 2018). Однако для многих задач генерации текста общего формата эталонные данные могут быть недоступны, что ограничивает применимость таких методов. Например, в диалоговых системах реального времени, таких как чат-боты, модель часто генерирует ответы без возможности сравнения с эталоном. 

\item Безэталонная детекция галлюцинаций (reference-free hallucination detection) 
   В условиях, где эталонные данные отсутствуют, используются методы безэталонной детекции галлюцинаций, которые основываются только на контексте и правилах, встроенных в модель. Такие подходы становятся актуальными в системах, работающих в реальном времени (например, чат-боты и системы авто-заполнения текста), где сравнение с эталоном затруднено из-за невозможности получить эталонные данные. Эти методы направлены на определение неконсистентных и потенциально ложных утверждений исключительно по информации, доступной модели в контексте текущего сеанса взаимодействия.
\end{enumerate}

Галлюцинации можно классифицировать по следующей структуре:
    \begin{itemize}
        \item Intrinsic галлюцинации (внутренние галлюцинации) внутри себя делятся на:
        \begin{itemize}
            \item Input-conflict галлюцинации
        — это случай, когда генерируемый текст не соответствует запросу пользователя. 
            \item Context-conflict галлюцинации - случай, когда модель генерирует высказывание, противоречащее ранее сгенерированной информации.
        \end{itemize}
        
        \item Extrinsic (fact-conflict) галлюцинации (внешние галлюцинации) — эти галлюцинации определяются различно в зависимости от задачи:
            \begin{itemize}
                \item генерируемый текст не соответствует фактам реального мира (для referenced-free постановки задачи),
                \item генерируемый текст не может быть подтвержден информацией, содержащейся во входных данных - эталонном документе (для reference-based постановки).
            \end{itemize}
    \end{itemize}

Кроме того, подходы к решению задачи детекции галлюцинации можно поделить на два вида по степени детальности обнаружения:
\begin{itemize}
   \item Уровень предложений или документов: Многие подходы, такие как детекция фейковых новостей (Zellers et al., 2019) или факт-чекинг (Thorne и Vlachos, 2018), анализируют галлюцинации на уровне предложения или всего документа. Однако такой подход может быть недостаточно точным для выявления конкретных ложных утверждений внутри текста, так как он оценивает весь текст в целом.
   \item Детекция на уровне токенов: В альтернативных методах детекция галлюцинаций осуществляется на уровне отдельных токенов. Такой подход позволяет более точно идентифицировать ложные утверждения в тексте и, в некоторых случаях, корректировать сгенерированный текст в реальном времени (например, управляя вероятностью появления тех или иных токенов). Этот метод более эффективен для задач, требующих высокую точность детекции и исправления, таких как системы генерации текста реального времени.
\end{itemize}
\subsection{Цель работы}
Reference-free постановка задачи являются более сложной с той точки зрения, что в ней не задан документ-образец, относительно которого идёт поиск галлюцинаций. Из-за этого качество таких моделей ниже. В данной работе исследуются различные решения для reference-free задач (Question Answering и детекция фактологических ошибок) и предлагается подход со сведением её к reference-based постановке. Кроме того, задача решается на уровне токенов, в token-classification постановке, что дополнительно усложняет решение задачи и делает исследование особенно ценным и комплексным.

 
\section{Постановка задачи}

Пусть заданы:
\begin{itemize}
    \item Запрос пользователя (query, промпт, задача) - последовательность токенов $Q = \{q_1,...,q_m\}$, где $m$ - длина последовательности.
    \item Ответ модели - последовательность токенов $X = \{x_1, x_2, . . . , x_n\}$, где $n$ - длина последовательности.
\end{itemize} 
Задача детекции галлюцинаций заключается в поиске всех пар вида $(i_k , j_k)$, где $i_k$ и $j_k$, такие что $i_k \leqslant j_k$ - индексы начала и конца текстового фрагмента $\overline{x_{i_k}x_{i_k+1}...x_{j_k}}$, являющегося галлюцинацией.

Предполагается отсутствие вложенных сущностей (плоская задача NER), поэтому постановка выше эквивалентна следующей: 
\\
Задача детекции галлюцинаций заключается в классификации каждого токена ответа \( X = \{x_1, x_2, \ldots, x_n\} \) на один из 3-х классов \( y_i \in \{B, I, O\} \), где \( B \) обозначает начало галлюцинации, \( I \) — продолжение галлюцинации, а \( O \) — токен, не являющийся частью галлюцинации.

%
%\section{Обзор существующих методов}
%dfgdfgdgfd\cite{abaho2021detect}fkgdfgdfgdfg
%

\cite{baly2020we}
 
\section{Предложенный метод}
\subsection{Instruction-based подход}
В предложенном подходе для детекции галлюцинаций используется instruction-based метод, при котором большая языковая модель (LLM) генерирует текст, явно указывая на галлюцинации в ответе. В данном эксперименте вместо вывода вероятностей или меток на уровне токенов модель на естественном языке выделяет фрагменты текста, которые, по её мнению, являются галлюцинациями.

Одним из ключевых свойств крупных языковых моделей является способность решать задачи, на которые они не были специально обучены, используя инструкции (промпты), формирующие поведение модели в ходе генерации текста. \\
Исследования по подбору промпта широко развились \cite{reynolds2021promptprogramminglargelanguage, liu2021pretrainpromptpredictsystematic} и получили термин ``prompt engineering'', а способность генеративных моделей проявлять умения, которые от них не требовались при обучении, получила название эмерджентным поведением (emergent behavior) и повлекло множество исследований \cite{wei2022emergentabilitieslargelanguage, openai2024gpt4technicalreport}.

\\
\textbf{Формирование промпта для явной индикации галлюцинаций}:
   Данные в задаче представляют из себя наборы пар: запрос пользователя \( Q = \{q_1, q_2, \dots, q_m\} \) и ответ модели \( X = \{x_1, x_2, \dots, x_n\} \). Задача состоит в создании промпта \( P \), который направит модель на явное указание фрагментов, являющихся галлюцинациями, и покажет наилучшее качество по описанным ниже метрикам.
   
\textbf{Преимущества и недостатки instruction-based метода}

\begin{itemize}
    \item \textbf{Преимущества:}
    \begin{itemize}
        \item \textbf{Адаптивность:} позволяет модели решать задачи, на которые она не была специально обучена, благодаря использованию промптов.
        \item \textbf{Экономичность:} отсутствует необходимость в дообучении модели, что снижает затраты на дополнительные данные и вычислительные ресурсы.
        \item \textbf{Универсальность:} подходит для широкого спектра задач, где можно управлять поведением модели через промпты.
        \item \textbf{Интерпретируемость:} модель может выдавать галлюцинации в явном виде, делая выводы более прозрачными для пользователей.
    \end{itemize}
    
    \item \textbf{Недостатки:}
    \begin{itemize}
        \item \textbf{Чувствительность к формулировке промпта:} результат может сильно зависеть от точной формулировки запроса, что требует времени на подбор оптимальных инструкций.
        \item \textbf{Отсутствие гарантий точности:} модель может ошибаться в детекции галлюцинаций, так как метод не обеспечивает вероятностных оценок надёжности.
        \item \textbf{Ограниченная гибкость:} сложно управлять степенью уверенности модели в предсказаниях без дополнительных вероятностных данных.
        \item \textbf{Зависимость от масштабов модели:} для эффективного выполнения задачи могут требоваться крупные модели, что увеличивает вычислительные затраты.
    \end{itemize}
\end{itemize}

\subsection{Обучение рекуррентной нейросети LSTM}

Для данных, в которых помимо сгенерированного ответа модели известны логиты (или вероятности) каждого токена, можно провести эксперименты с обучением моделей, анализирующих лишь временной ряд логитов. В данном случае данные представляют собой последовательность логитов и соответствующую последовательность истинных меток, которые модель должна предсказать.

Архитектура модели включает слой LSTM, после которого добавляется линейный слой, понижающий размерность до 1, что позволяет получить вероятность для каждого токена. Модель обучается с использованием функции потерь BCE (Binary Cross-Entropy Loss), которая минимизируется по следующей формуле:

\[
\text{BCE Loss} = -\frac{1}{N} \sum_{i=1}^{N} \left( y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right)
\]

где:
\begin{itemize}
    \item \( N \) — количество токенов в обучающей выборке,
    \item \( y_i \) — истинная метка для токена \( i \) (1 для галлюцинации, 0 для корректного токена),
    \item \( \hat{y}_i \) — предсказанная моделью вероятность того, что токен \( i \) является галлюцинацией.
\end{itemize}

Таким образом, модель на базе LSTM обучается на последовательности логитов для детекции галлюцинаций, опираясь на временные зависимости между логитами.

\textbf{Плюсы и минусы подхода}\\
\textbf{Плюсы:}
    \begin{itemize}
        \item Использование только логитов позволяет модели анализировать временные зависимости без учёта лексического содержания, что снижает влияние языковых особенностей и позволяет концентрироваться на статистических особенностях.
        \item Архитектура LSTM позволяет учитывать долгосрочные зависимости в последовательностях, что полезно для обнаружения скрытых закономерностей в логитах, связанных с галлюцинациями.
    \end{itemize}
\textbf{Минусы:}
    \begin{itemize}
        \item Отсутствие информации о самих токенах может ограничивать точность, так как модель не учитывает семантический контекст слов.
        \item Обучение на логитах может быть более подвержено шуму и нестабильности, особенно если логиты не отражают чёткой разницы между галлюцинациями и корректными ответами.
        \item Для эффективного обучения может потребоваться большой объём данных, так как модель анализирует только числовые представления (логиты) без дополнительных подсказок из текста.
    \end{itemize}

Модель LSTM была представлена в 1997 году \cite{lstm} и получила широкую известность и область применения. Схема её архитектуры и основные слои представлены на рис. \ref{fig:LSTM}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/LSTM.PNG}
    \caption{Архитектура нейросети LSTM}
    \label{fig:LSTM}
\end{figure}

\subsection{Дообучение NER моделей}
Задача выделения фрагментов галлюцинаций в тексте представляет собой задачу классификации токенов, в которой каждому токену присваивается метка, указывающая, является ли он частью галлюцинации или нет. Для решения этой задачи используется формат BIO-разметки (отмечающий начало, середину и конец фрагментов, содержащих галлюцинации). Формат BIO позволяет более точно определять начало и границы фрагментов и показывает лучшие результаты в сравнении с форматом бинарной классификации каждого токена. В данном разделе мы подробно опишем задачу обучения модели и введем основные обозначения.

\textbf{Формализация задачи}


Рассмотрим текст, состоящий из \( N \) токенов, представленных последовательностью \( X = (x_1, x_2, \ldots, x_N) \). Модель должна классифицировать каждый токен \( x_i \) как принадлежащий галлюцинации или нет, используя BIO-формат, где:
\begin{itemize}
\item \textbf{B} обозначает начало фрагмента галлюцинации,
\item \textbf{I} обозначает токен, продолжающий галлюцинацию,
\item \textbf{O} обозначает токен, не связанный с галлюцинацией.
\end{itemize}
Для этого модель обучается предсказывать вероятности \( \hat{S} \) для каждого токена текста.

\textbf{Обозначения матриц меток и предсказаний:}

\( S \in \{0, 1\}^{N \times 3} \): бинарная матрица, содержащая истинные метки для каждого токена, где:
   \begin{itemize}
     \item \( S_{i,0} = 1 \), если токен \( x_i \) отмечен как \textbf{B},
     \item \( S_{i,1} = 1 \), если токен \( x_i \) отмечен как \textbf{I},
     \item \( S_{i,2} = 1 \), если токен \( x_i \) отмечен как \textbf{O}.
   \end{itemize}
\( \hat{S} \in [0, 1]^{N \times 3} \): матрица предсказаний модели, где \( \hat{S}_{i,t} \) обозначает вероятность того, что токен \( x_i \) относится к классу \( t \in \{ B, I, O \} \).

\textbf{Ограничения нормировки:}

   Для каждого токена модель должна предсказывать распределение вероятностей по трем меткам, что выражается следующим условием:
   $$
   \sum_t \hat{S}_{i, t} = 1, \quad \forall i \in \{1, \dots, N\}
   $$

\textbf{Функция потерь — кросс-энтропия:}

   Для оптимизации параметров span-detection моделей используется функция потерь на основе кросс-энтропии, которая минимизируется по параметрам модели \( \theta' \):
   $$
   CE(S, \hat{S}) = -\frac{1}{N} \sum_{i=1}^{N} \sum_{t \in \{B, I, O\}} S_{i, t} \log(\hat{S}_{i, t})
   $$
   Здесь:
   - \( S_{i, t} \) — бинарный индикатор для истинной метки токена \( x_i \) по классу \( t \),
   - \( \hat{S}_{i, t} \) — вероятность, предсказанная моделью для метки \( t \) токена \( x_i \).

И задача обучения модели заключается в поиске параметров, доставляющих минимум функции потерь:
$$
CE(S, p(S \mid \theta)) = CE(S, \hat{S}) = -\frac{1}{N} \sum_{i=1}^{N} \sum_{t \in \{B, I, O\}} S_{i, t} \log(\hat{S}_{i, t}) \longrightarrow \min_{\theta}
$$

\subsection{Методика оценивания модели}
\textbf{Обозначения для i-го класса:}
\begin{itemize}
    \item True Positive $(TP_i)$: количество токенов или фрагментов, которые модель правильно классифицировала как принадлежащие классу $i$. Определяется как количество случаев, в которых предсказанный класс и истинный класс равны $i$:
    \[
    TP_i = \sum_{j=1}^{N} \mathbb{I}(\hat{y}_j = i \land y_j = i)
    \]
    где $N$ — общее количество токенов, $\hat{y}_j$ — предсказанный класс для токена $j$, $y_j$ — истинный класс для токена $j$, а $\mathbb{I}(\cdot)$ — индикаторная функция, принимающая значение 1, если условие выполняется, и 0 в противном случае.

    \item False Positive $(FP_i)$: количество токенов или фрагментов, которые модель ошибочно классифицировала как принадлежащие классу $i$. Определяется как количество случаев, в которых предсказанный класс равен $i$, но истинный класс не равен $i$:
    \[
    FP_i = \sum_{j=1}^{N} \mathbb{I}(\hat{y}_j = i \land y_j \neq i)
    \]

    \item False Negative $(FN_i)$: количество токенов или фрагментов, которые модель ошибочно не отнесла к классу $i$. Определяется как количество случаев, в которых истинный класс равен $i$, но предсказанный класс не равен $i$:
    \[
    FN_i = \sum_{j=1}^{N} \mathbb{I}(\hat{y}_j \neq i \land y_j = i)
    \]
\end{itemize}


\textbf{Метрики для i-го класса:}

1. Точность (Precision) для \( i \)-го класса: Точность показывает, какая доля токенов, предсказанных моделью как относящиеся к классу \( i \), действительно относятся к этому классу.
\[
\text{Precision}_i = \frac{TP_i}{TP_i + FP_i}
\]

2. Полнота (Recall) для \( i \)-го класса: Полнота показывает, какую долю токенов класса \( i \) модель правильно предсказала, по отношению к общему числу токенов данного класса в данных.
\[
\text{Recall}_i = \frac{TP_i}{TP_i + FN_i}
\]

3. F1-score для \( i \)-го класса: F1-score является гармоническим средним точности и полноты и даёт общую оценку качества предсказания для класса \( i \).
\[
\text{F1}_i = 2 \cdot \frac{\text{Precision}_i \cdot \text{Recall}_i}{\text{Precision}_i + \text{Recall}_i}
\]

\textbf{Общие метрики для всех классов:}

4. F1-macro (макроусреднённый F1-score): F1-macro вычисляется как среднее значение F1-score по всем классам, где каждый класс имеет одинаковый вес. Это полезно, когда важно учитывать качество предсказаний для каждого класса независимо от его размера.
\[
\text{F1-macro} = \frac{1}{C} \sum_{i=1}^{C} \text{F1}_i
\]
где \( C \) — количество классов.

5. F1-micro (микроусреднённый F1-score): F1-micro учитывает общие суммы \( TP \), \( FP \) и \( FN \) по всем классам и вычисляет F1 на основе общей точности и полноты. Он полезен, когда важен вклад каждого примера, вне зависимости от размера класса.
\[
\text{F1-micro} = \frac{2 \cdot \sum_{i=1}^{C} TP_i}{2 \cdot \sum_{i=1}^{C} TP_i + \sum_{i=1}^{C} FP_i + \sum_{i=1}^{C} FN_i}
\]

Дополнительно рассматривается задача, в которой для каждого фрагмента текста указана степень уверенности, с которой он был отнесён к галлюцинации. Чтобы оценить качество модели в таких случаях, используется корреляция Спирмана, которая позволяет измерить степень согласованности между ранжированными предсказаниями модели и истинными значениями.

Пусть имеются следующие значения для $N$ фрагментов:
\begin{itemize}
    \item $r_i$ — ранг степени уверенности для $i$-го фрагмента, предсказанный моделью,
    \item $s_i$ — истинный ранг степени уверенности для $i$-го фрагмента.
\end{itemize}

Корреляция Спирмана (\( \rho \)) рассчитывается по формуле:
\[
\rho = 1 - \frac{6 \sum_{i=1}^{N} (r_i - s_i)^2}{N (N^2 - 1)}
\]

где $N$ — количество фрагментов. Данная формула основывается на квадрате разницы между рангами предсказанных и истинных значений и позволяет оценить, насколько предсказанные уверенности соответствуют истинным.

Критерий \textbf{IoU} (Intersection over Union, пересечение над объединением) используется для оценки схожести предсказанных и истинных фрагментов. IoU измеряет долю пересечения между предсказанным фрагментом и истинным фрагментом от их объединения. Формула IoU определяется как:

\[
\text{IoU} = \frac{|A \cap B|}{|A \cup B|}
\]

где:
\begin{itemize}
    \item \( A \) — множество токенов, принадлежащих истинному фрагменту галлюцинации.
    \item \( B \) — множество токенов, принадлежащих предсказанному фрагменту галлюцинации.
    \item \( |A \cap B| \) — количество токенов, которые находятся одновременно в истинном и предсказанном фрагментах.
    \item \( |A \cup B| \) — количество токенов, которые находятся хотя бы в одном из фрагментов (их объединение).
\end{itemize}

Для задачи с несколькими фрагментами галлюцинаций метрика IoU может быть усреднена по всем парам предсказанных и истинных фрагментов, чтобы получить средний IoU. 



 
\section{Вычислительный эксперимент}
\subsection{Данные}
\subsubsection{SemEval-2025}
В рамках активного соревнования Semeval-2025(\url{https://helsinki-nlp.github.io/shroom/}) на момент написания статьи доступна размеченная валидационная выборка. Она состоит из 10 файлов на разных языках. В каждом файле 50 объектов-троек: вопрос-ответ-размеченные галлюцинации.
\subsection{Instruction-based подход}
Для проведения эксперимента выбрана модель Meta-Llama-3.1-8B-Instruct. Модель была представлена в 2024 году, обучалась на данных до декабря 2023 года и содержит одни из самых актуальных знаний среди больших языковых моделей, а также показывает высокие результаты на бенчмарках. Кроме того, платформа kaggle с видеокартой Nvidia P100 с 16 Gb видеопамяти добавляет ограничения на размер модели, и Llama-3.1-8B занимает всю доступную видеопамять. Так, для экспериментов была выбрана эта модель как наиболее актуальная и мощная из возможных для запуска на kaggle.

Для эксперимента взяты 50 объектов на английском языке из валидационной выборки соревнования SemEval-2025 и проведено множество экспериментов с промптами. Наилучший результат достигнут для следующего промпта:

\texttt{messages = [
    \{``role'': ``system'', ``content'': ``You are a fact-checking assistant. Your task is to identify fragments of the response that are hallucinations -- parts of the text that are factually incorrect or made up by model. Pay attention to facts, dates, numbers, places. Detect only hallucination words, without neighbour words. Give me only a list of fragments-hallucinations you found in model output.''\},
    \{``role'': ``user'', ``content'': formatted\_str\},
]}

В \texttt{formatted\_str} подавалась строка следующего вида:\\
\texttt{formatted\_str = ``query'':``\{data[``model\_input'']\}'' ``model\_output'':\\``\{data[``model\_output\_text'']\}''}

Для оценки качества по регламенту конкурса используется метрика IoU. 

Результаты: распределение IoU на объектах в данном эксперименте представлено на рис. \ref{fig:ious_histogram}.\\ Средний IoU составил \textbf{39.7\%}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/ious_histogram.pdf}
    \caption{распределение IoU на объектах SemEval-2025.}
    \label{fig:ious_histogram}
\end{figure}

\subsection{Обучение рекуррентной нейросети LSTM}
Для проведения эксперимента была выбрана реализация модели LSTM из библиотеки torch: \texttt{torch.nn.LSTM}. На выходы LSTM добавляется линейный слой \texttt{torch.nn.Linear}, понижающий размерность до 1. Аналогично предыдущему эксперименту, использовалась платформа Kaggle. 

В качестве данных взята валидационная выборка на всех языках от конкурса SemEval-2025. Выборка составила 500 объектов. Выборка поделена на обучающую и тестовую в соотношении 9:1. Обучение длилось 50 эпох. 

Кривые процесса обучения представлены на графиках \ref{fig:ious_train}, \ref{fig:loss_train}. Качество обученной модели на валидационной выборке  $\text{IoU}=15.5\%$.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/iou_plot (1).pdf}
    \caption{График зависимости IoU от эпохи на обучающей и тестовой выборках.}
    \label{fig:ious_train}
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/loss_plot (1).pdf}
    \caption{График зависимости BCE Loss от эпохи на обучающей и тестовой выборках.}
    \label{fig:loss_train}
\end{figure}

 \subsection{Дообучение  NER модели}
\section*{Данные}
В качестве данных использовался набор HaluEval, переразмеченный в формат классификации токенов с помощью GPT-4. В итоговом датасете содержится 10 000 объектов, представляющих собой пары (вопрос, ответ, фрагменты галлюцинации). Данные были разделены на обучающую и тестовую выборки в соотношении 9:1.

\section*{Настройки обучения}
Для обучения модели \texttt{distilbert-base-uncased} использовались следующие гиперпараметры:
\begin{itemize}
\item Количество эпох: 3
\item Количество шагов разогрева: 500
\item Коэффициент затухания весов: 0.01
\item Размер батча на устройство: 16
\end{itemize}

\section*{Результаты}
Качество обученной модели было оценено на тестовой выборке. Основные метрики приведены ниже:
\begin{itemize}
\item \textbf{Accuracy:} 0.94
\item \textbf{F1 Macro:} 0.810
\item \textbf{F1 Micro:} 0.939
\item \textbf{IoU:} 0.711
\end{itemize}

\section*{Графики обучения}
Процесс обучения представлен на графиках. На Рисунке~\ref{fig:loss_train} показана динамика функции потерь BCE на обучающей выборке, а на Рисунке~\ref{fig:val_loss} --- на валидационной выборке.
\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{W&B Chart 22.11.2024, 17_47_03.png}
\caption{BCE Loss на обучающей выборке.}
\label{fig:loss_train}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{W&B Chart 22.11.2024, 17_48_48.png}
\caption{BCE Loss на валидационной выборке.}
\label{fig:val_loss}
\end{figure}

\section*{Классификационный отчёт}
Для более детального анализа работы модели был сформирован классификационный отчёт, представленный в Таблице~\ref{tab:classification_report}.
\begin{table}[ht]
\centering
\begin{tabular}{lcccc}
\toprule
 & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\
\midrule
0 & 0.95 & 0.98 & 0.97 & 34944 \\
1 & 0.77 & 0.57 & 0.65 & 3911 \\
\midrule
\textbf{Macro Avg} & 0.86 & 0.77 & 0.81 & 38855 \\
\textbf{Weighted Avg} & 0.93 & 0.94 & 0.94 & 38855 \\
\bottomrule
\end{tabular}
\caption{Классификационный отчёт}
\label{tab:classification_report}
\end{table}

\subsection{Сравнение рассмотренных методов}

В таблице~\ref{tab:comparison} представлены результаты работы моделей LSTM, Llama-3.1-8B и DistilBERT на различных датасетах. Для оценки использованы метрики F1 Macro и IoU.

\begin{table}[ht]
    \centering
    \begin{tabular}{lccc}
        \toprule
        \textbf{Модель} & \textbf{HaluEval} (val) & \textbf{SemEval-500} & \textbf{SemEval-50} (Eng) \\
        \midrule
        LSTM & -- & 0.23~/~0.155 & 0.25~/~0.19 \\
        Llama-3.1-8B & 0.722~/~0.693 & \textbf{0.398~/~0.375} & \textbf{0.421~/~0.397} \\
        DistilBERT & \textbf{0.810~/~0.711} & 0.303~/~0.281 & 0.361~/~0.332 \\
        \bottomrule
    \end{tabular}
    \caption{F1 Macro и IoU для всех моделей на различных датасетах}
    \label{tab:comparison}
\end{table}

Анализ таблицы~\ref{tab:comparison} позволяет сделать следующие выводы:
\begin{itemize}
    \item \textbf{Устойчивость данных:} Модель Llama-3.1-8B показала наилучшую устойчивость к различным форматам данных, превосходя остальные модели на датасетах SemEval-500 и SemEval-50.
    \item \textbf{Специализация на обучающей выборке:} Модель DistilBERT превосходит Llama-3.1-8B по метрикам на датасете HaluEval, схожем с обучающей выборкой, но демонстрирует худшие результаты на других датасетах, что указывает на меньшую способность к обобщению.
    \item \textbf{Производительность LSTM:} Модель LSTM существенно уступает современным подходам по качеству, что делает её использование нецелесообразным.
\end{itemize}

 
\section{Заключение}

В данной работе проведено исследование методов детекции галлюцинаций в token classification постановке с акцентом на фактологические галлюцинации в reference-free задачах. В рамках исследования были проанализированы и сравнены три подхода: instruction-based использование больших языковых моделей (LLM), дообучение моделей NER, а также анализ временных рядов. Сравнительный анализ подтвердил, что успешное решение reference-free задач требует компромисса между качеством детекции, вычислительной эффективностью и способностью модели к обобщению. Instruction-based подходы предоставляют универсальность и высокое качество, однако требуют значительных ресурсов. В то же время компактные NER модели могут быть эффективными в задачах с качественно размеченными обучающими выборками, оставаясь более лёгкими для развёртывания. Дальнейшие исследования будут направлены на построение и сравнение RAG (retrieval augmented generation) систем, объединяющих векторные базы данных и модели детекции.

\bibliographystyle{splncs04}
\bibliography{references}

 
\section{Приложение}

\end{document}