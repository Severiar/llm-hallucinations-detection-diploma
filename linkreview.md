| Название | Год | Автор | Ссылка | Краткое содержание |
| -------- |---- | ----- | ------ | ---- |
|Developing a Reliable, General-Purpose Hallucination Detection and Mitigation Service: Insights and Lessons Learned| 22 Jul 2024 |Song Wang, Xun Wang, Jie Mei, Yujia Xie, Sean Muarray, Zhang Li, Lingfeng Wu, Si-Qing Chen, Wayne Xiong|[link](https://arxiv.org/abs/2407.15441)|Построение системы выявления и устранения галлюцинаций LLM в задаче суммаризации текста. Решение для детекции галлюцинаций - ансамбль моделей: NER (Named Entity Recognition), NLI (Natural Language Inference), SBD (Span-based detection) - ключевая для нас часть, GBDT (Gradient Boosting Decision Tree). Решение для устранения галлюцинаций - повторная генерация ответа на основе промпта, сформированного от ансамбля моделей-детекторов.|
| GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework | 15 Jul 2024 | Hannah Sansford, Nicholas Richardson, Hermina Petric Maretic, Juba Nait Saada | [link](https://arxiv.org/abs/2407.10793) | Цель: построить максимально гибкое и легковесное решение детекции галлюцинаций в тексте с явным выделением фрагментов, посредством построения Knowledge Graph входного текста. Пайплайн решения: 1. Выделение NER, NER-Relations, CoRepherences 2. Построение Knowledge Graph на тройках entity - relation - entity 3. Использование NLI моделей или прочих для анализа троек на предмет галлюцинаций в них |
| A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation | 18 Apr 2021 | Tianyu Liu, Yizhe Zhang, Chris Brockett, Yi Mao, Zhifang Sui, Weizhu Chen, Bill Dolan | [link](https://arxiv.org/abs/2104.08704) | Создали датасет HADES - выделены галлюцинации в формате Span ID, и провели множество экспериментов с базовыми моделями в Span ID задаче. |
| Neural Path Hunter: Reducing Hallucination in Dialogue Systems via Path Grounding | 17 Apr 2021 | Nouha Dziri, Andrea Madotto, Osmar Zaiane, Avishek Joey Bose | [link](https://arxiv.org/abs/2104.08455) | Построение Knowledge Graph на основе k-hop graph подхода для детекции внешних галлюцинаций в диалоговых системах |
| Hallucinated but Factual! Inspecting the Factuality of Hallucinations in Abstractive Summarization | 06 Dec 2021 | Meng Cao, Yue Dong, Jackie Chi Kit Cheung | [link](https://arxiv.org/abs/2109.09784) | Рассматривается задача поиска галлюцинаций в суммаризации текстов. Анализ сущностей-галлюцинаций, подход с априорным и апостериорным распределением. Строится модель EntFA - Entity Factuality Assessment. Рассматривается Reinforcement Learning подход.  |
| HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models | 19 May 2023 | Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, Ji-Rong Wen | [link](https://arxiv.org/abs/2305.11747) | Строят крупнейший бенчмарк по теме галлюцинаций. Дополнительно с ручной валидацией. Бенчмарк содержит несколько доменов:  |
| MedHalu: Hallucinations in Responses to Healthcare Queries by Large Language Models | 28 Sep 2024 | Vibhor Agarwal, Yiqiao Jin, Mohit Chandra, Munmun De Choudhury, Srijan Kumar, Nishanth Sastry |[link](https://arxiv.org/abs/2409.19492) | Строят фреймворк MedHalu для нескольких доменов по теме здоровья: HealthQA, LiveQA, MedicationQA. Исследуют качество генеративных моделей на этих фремворках |
| Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models | 1 Apr 2024 | Miaoran Li, Baolin Peng, Michel Galley, Jianfeng Gao, Zhu Zhang |[link](https://arxiv.org/abs/2305.14623) | Строят модуль-надстройку над генеративными моделями, исправляющую фактологические ошибки. Эксперементируют с разными промптами и декларируют универсальность модуля для многих LLM |
| SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models | 11 Oct 2023 | Potsawee Manakul, Adian Liusie, Mark J. F. Gales | [link](https://arxiv.org/abs/2303.08896) | Строят модуль-надстройку над LLM, которая по запросу пользователя и ответу LLM генерирует несколько новых ответов, сравнивает их согласованность и на основе этого принимает решение о наличии галлюцинаций |
| Survey of Hallucination in Natural Language Generation | 14 Jul 2024 | Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Delong Chen, Wenliang Dai, Ho Shu Chan, Andrea Madotto, Pascale Fung | [link](https://arxiv.org/abs/2202.03629) | Фундаметальный и всеобъемлющий обзор всех известных подходов по детекции галлюцинаций. Рассматриваются всевозможные постановки задач и предложенные решения авторов. Классификация и таксономия галлюцинаций |
| AlignScore: Evaluating Factual Consistency with a Unified Alignment Function | 26 May 2023 | Yuheng Zha, Yichi Yang, Ruichen Li, Zhiting Hu | [link](https://arxiv.org/abs/2305.16739) | Фокусируются на внутренних галлюцинациях: строят Alignment функцию для оценки согласованности вопроса пользователя и сгенерированного ответа. Тестируют на огромном количестве фреймворков и для разных доменов данных. | 
| Automatic Calibration and Error Correction for Large Language Models via Pareto Optimal Self-Supervision | 22 May 2024 | Theodore Zhao, Mu Wei, J. Samuel Preston, Hoifung Poon | [link](https://arxiv.org/abs/2306.16564) | Решают задачу детекции галлюцинаций в document-classification поставновке. При этом используют очень неожиданный подход - из экономики - Парето-оптимальную вероятностную модель. При этом выводят теоретические оценки для своей модели, показывают её высокое качество, сравнивают RAG / no RAG подходы | 
| Controlling Hallucinations at Word Level in Data-to-Text Generation | 9 Jul 2021 | Clément Rebuffel, Marco Roberti, Laure Soulier, Geoffrey Scoutheeten, Rossella Cancelliere, Patrick Gallinari | [link](https://arxiv.org/abs/2102.02810) | Детекция галлюцинаций в необычной задаче - Data-to-Text Generation - по карточке пользователя (фактически, табличные данные) нужно на естественном языке её описать. Решают задачу на word-level уровне, активно используют синтаксический разбор предложения и классические подходы из лингвистики | 
| Long Short-term Memory | Dec 1997 | Hochreiter, Sepp and Schmidhuber, Jürgen | [link](10.1162/neco.1997.9.8.1735) | Они придумали LSTM, а ты даже не знаешь их имён. Это база, не нуждающаяся в представлении. Модель положила основу современным генеративным моделям. Использовалась в экспериментах данной работы, поэтому оставляю ссылку на статью по LSTM  |
| GPT-4 Technical Report | 4 Mar 2024 | OpenAI, Josh Achiam, Steven Adler et al. | [link](https://arxiv.org/abs/2303.08774) | Большой технический отчет по одной из самых сильных LLM на 2024 год. Отчёт - без технических деталей обучения. Модель используется в моём исследовании. |
| Emergent Abilities of Large Language Models | 26 Oct 2022 | Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph | [link](https://arxiv.org/abs/2206.07682) | Исследуется интересное явление сверхбольших генеративных моделей - эмерджентное поведение - способность решать задачи, на которые модель не обучалась. Эта способность используется в экспериментах по токен-классификации с помощью LLM в моей работе  |
